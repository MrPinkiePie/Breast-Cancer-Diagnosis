# üéóÔ∏è Breast Cancer Diagnosis: Support Vector Machines (SVM)

![Python](https://img.shields.io/badge/Python-3.10-blue?style=flat&logo=python)
![Scikit-Learn](https://img.shields.io/badge/Library-Scikit--Learn-orange?style=flat&logo=scikit-learn)
![Model](https://img.shields.io/badge/Model-SVM-green)
![Status](https://img.shields.io/badge/Status-Completado-success)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1fYctXU9222vshA7wbC2ZnKZxDx6e3ROh?usp=sharing)

## üìã Descripci√≥n del Proyecto
Este proyecto aplica algoritmos de **Support Vector Machines (SVM)** para asistir en el diagn√≥stico m√©dico de c√°ncer de mama. Utilizando el dataset *Wisconsin Diagnostic Breast Cancer (WDBC)*, el objetivo no es solo la exactitud t√©cnica, sino la **seguridad cl√≠nica**: priorizar la detecci√≥n de todos los casos malignos (Recall) para salvar vidas.

Este trabajo marca una transici√≥n en mi portafolio, pasando de modelos basados en √°rboles (XGBoost/Random Forest) a modelos basados en geometr√≠a y m√°rgenes, ideales para datasets de alta dimensionalidad.

## üè• Contexto y Problem√°tica
En el diagn√≥stico oncol√≥gico, los errores de predicci√≥n tienen costos asim√©tricos extremos:
* **Falso Positivo (Error Tipo I):** Diagnosticar a un paciente sano como enfermo. Conlleva costos econ√≥micos y ansiedad, pero no es letal.
* **Falso Negativo (Error Tipo II):** Diagnosticar a un paciente con c√°ncer como sano. **Este error es inaceptable**, ya que retrasa el tratamiento.

**Objetivo:** Desarrollar un clasificador binario que maximice el **Recall (Sensibilidad)**, minimizando los Falsos Negativos.

## ‚öôÔ∏è Estrategia de Modelado
Se eligi√≥ SVM con kernel **RBF** por su robustez en espacios de alta dimensionalidad (30 features).

### Decisiones T√©cnicas Clave:
1.  **Estandarizaci√≥n Rigurosa (`StandardScaler`):** SVM se basa en distancias euclidianas. Variables de gran magnitud (ej. √Årea ~1000) dominar√≠an sobre las peque√±as (ej. Simetr√≠a ~0.1). Se escalaron todas las caracter√≠sticas.
2.  **Manejo del Desbalance (`class_weight='balanced'`):** Se penaliz√≥ el error en la clase minoritaria (Maligno) para forzar al modelo a prestarle atenci√≥n.
3.  **Regularizaci√≥n Conservadora (`C=0.1`):** Se opt√≥ por un margen "suave" (Soft Margin). Esto crea un modelo m√°s generalista que prefiere tolerar algunos errores en el entrenamiento a cambio de no sobreajustarse al ruido (evitando Overfitting).
4.  **Optimizaci√≥n:** `GridSearchCV` optimizando espec√≠ficamente la m√©trica `Recall`.

## üìÇ Sobre el Dataset
**Fuente:** [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29)
* **Instancias:** 569 pacientes.
* **Target:** Diagnosis (M = Malignant, B = Benign).
* **Features:** 30 caracter√≠sticas geom√©tricas computadas a partir de im√°genes digitalizadas de aspirados con aguja fina (FNA).

## üõ†Ô∏è Stack Tecnol√≥gico
* **Procesamiento:** Pandas, NumPy.
* **Visualizaci√≥n:** Seaborn, Matplotlib.
* **Preprocesamiento:** `StandardScaler`.
* **Modelado:** `SVC` (Scikit-Learn).
* **Interpretaci√≥n:** `permutation_importance`, `PCA`.

## üìà Resultados del Modelo
El modelo final logr√≥ un equilibrio robusto para un entorno de asistencia m√©dica:

| M√©trica | Valor | Interpretaci√≥n |
| :--- | :--- | :--- |
| **Recall (Sensibilidad)** | **~95%** | El modelo detecta casi la totalidad de los casos de c√°ncer. |
| **ROC - AUC** | **0.99** | Excelente capacidad de separaci√≥n entre clases sanas y enfermas. |
| **Accuracy** | **~87%** | Ligeramente menor debido al trade-off: se aceptan m√°s Falsos Positivos (baja precisi√≥n) para asegurar el alto Recall. |

**Mejores Hiperpar√°metros:**
* `C`: 0.1
* `gamma`: 0.1
* `kernel`: 'rbf'

## üîç Insights: ¬øQu√© define a un tumor maligno?
Mediante **Permutation Importance** y **PCA**, auditamos la "caja negra" del modelo:

### 1. Importancia de Variables
Al analizar qu√© variables impactan m√°s en el diagn√≥stico, descubrimos:
* **El peligro de lo "Peor" (`_worst`):** Las variables m√°s predictivas fueron `radius_worst`, `perimeter_worst` y `area_worst`. El modelo busca las c√©lulas m√°s grandes y an√≥malas de la muestra, no el promedio.
* **La forma importa:** La irregularidad del contorno (`concave_points`) es cr√≠tica. Los tumores malignos tienen bordes espiculados.
* **Ruido:** Variables como *Textura* o *Simetr√≠a* resultaron menos determinantes que la geometr√≠a f√≠sica.

### 2. Visualizaci√≥n 2D (PCA)
Se redujeron las 30 dimensiones a 2 Componentes Principales que explican el **~63% de la varianza**.
* **Conclusi√≥n Visual:** Existe una separaci√≥n geom√©trica clara entre los clusters de Benignos y Malignos, lo que justifica matem√°ticamente el alto rendimiento del SVM (AUC 0.99).

---
*Este proyecto fue desarrollado como parte de un portafolio de Data Science enfocado en la diversificaci√≥n de algoritmos de Machine Learning.*
